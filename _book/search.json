[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Parallel Practical",
    "section": "",
    "text": "1 Welcome to Parallel Prac\nGitHub Link",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome to Parallel Prac</span>"
    ]
  },
  {
    "objectID": "ParallelPrac.html",
    "href": "ParallelPrac.html",
    "title": "2  Q1",
    "section": "",
    "text": "2.1 Q2\nlibrary(MASS)\nlibrary(foreach)\nlibrary(doParallel)\n\n# Set up parallel processing \ncl &lt;- makeCluster(3)\nregisterDoParallel(cl)\n\n\nbootstrapMedian &lt;- function(data, n) {\n  sample_data &lt;- sample(data, size = n, replace = TRUE)\n  return(median(sample_data))\n}\n\n\nset.seed(42)  # For reproducibility\nsystem.time({\n  bootstrapped_medians_serial &lt;- sapply(1:1000, function(x) bootstrapMedian(galaxies, n = 82))\n})\n\n   user  system elapsed \n   0.08    0.00    0.08 \n\nprint(head(bootstrapped_medians_serial))\n\n[1] 20205.5 20208.5 20846.0 20522.0 20846.0 20221.0\n\n# Run bootstrapping in parallel\nlibrary(doParallel)\ncl &lt;- makeCluster(4)  \nregisterDoParallel(cl)\n\n\nset.seed(42)  \nsystem.time({\n  bootstrapped_medians_parallel &lt;- foreach(i = 1:1000, .combine = c, .packages = \"MASS\") %dopar% {\n    bootstrapMedian(galaxies, n = 82)\n  }\n})\n\n   user  system elapsed \n   0.42    0.10    0.70 \n\nstopCluster(cl)\n\n\nprint(head(bootstrapped_medians_parallel))\n\n[1] 20187.5 21757.5 20875.0 20712.0 20821.0 20930.5\nFor the current bootstrapping task with the galaxies dataset, serial execution is faster due to the small task size and the cost of parallelization overhead. If you were processing much larger datasets or running more complex computations, you would likely see greater benefits from parallelization.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Q1</span>"
    ]
  },
  {
    "objectID": "ParallelPrac.html#q3",
    "href": "ParallelPrac.html#q3",
    "title": "2  Q1",
    "section": "2.2 Q3",
    "text": "2.2 Q3\n\nset.seed(42)  # For reproducibility\n\noriginal_sample &lt;- rexp(50, rate = 1)  #\n\n\nbootstrap_mean &lt;- function(sample, n_iterations = 1000) {\n  bootstrap_stats &lt;- numeric(n_iterations)\n  \n  for (i in 1:n_iterations) {\n    bootstrap_sample &lt;- sample(sample, replace = TRUE)\n    bootstrap_stats[i] &lt;- mean(bootstrap_sample)  #\n  }\n  \n  return(bootstrap_stats)\n}\n\n\nn_iterations &lt;- 1000\nbootstrap_stats &lt;- bootstrap_mean(original_sample, n_iterations)\n\n\nlower_percentile &lt;- 2.5\nupper_percentile &lt;- 97.5\n\nlower_bound &lt;- quantile(bootstrap_stats, lower_percentile / 100)\nupper_bound &lt;- quantile(bootstrap_stats, upper_percentile / 100)\n\n\ntrue_value &lt;- 1\n\ncoverage &lt;- ifelse(true_value &gt;= lower_bound & true_value &lt;= upper_bound, 1, 0)\n\nn_trials &lt;- 1000\ncoverage_results &lt;- numeric(n_trials)\n\nfor (i in 1:n_trials) {\n  bootstrap_stats &lt;- bootstrap_mean(original_sample, n_iterations)\n  lower_bound &lt;- quantile(bootstrap_stats, lower_percentile / 100)\n  upper_bound &lt;- quantile(bootstrap_stats, upper_percentile / 100)\n  coverage_results[i] &lt;- ifelse(true_value &gt;= lower_bound & true_value &lt;= upper_bound, 1, 0)\n}\n\ncoverage_estimate &lt;- mean(coverage_results)\ncoverage_estimate\n\n[1] 1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Q1</span>"
    ]
  },
  {
    "objectID": "ParallelPrac.html#q4",
    "href": "ParallelPrac.html#q4",
    "title": "2  Q1",
    "section": "2.3 Q4",
    "text": "2.3 Q4\n\n# Load necessary packages\nlibrary(foreach)\nlibrary(doParallel)  # For parallel processing\nlibrary(iterators)    # For irnorm function\n\n# Set the seed for reproducibility\nset.seed(1234)\n\n# Register parallel backend (4 workers in this case)\ncl &lt;- makeCluster(4)\nregisterDoParallel(cl)\n\n# Create a list of 3 vectors, each containing 5 random variables from a normal distribution\nvectors &lt;- foreach(i = 1:3, .combine = 'list', .packages = 'iterators') %dopar% {\n  it &lt;- irnorm(5)  # Create an iterator for 5 random normal variables\n  unlist(sapply(1:5, function(x) nextElem(it)))  # Extract the values from the iterator\n}\n\n# Print the vectors to check\nprint(vectors)\n\n[[1]]\n[[1]][[1]]\n           [,1]       [,2]      [,3]       [,4]       [,5]\n[1,]  1.2784493 -0.8137028 0.1885588  0.6533295 -1.0311904\n[2,]  2.1939424  1.3281171 1.0740013 -2.1921191 -0.1345624\n[3,]  1.4756420  1.8995166 1.0001530 -1.3854213 -0.7265362\n[4,] -0.3266587  0.5621704 0.8023188  0.1446977  0.2316120\n[5,] -0.9967498  0.5050392 0.3150987  1.0641211 -0.9286140\n\n[[1]][[2]]\n           [,1]       [,2]       [,3]        [,4]       [,5]\n[1,]  1.1580120 0.22531528  2.6536696 -0.21807839  0.5134449\n[2,] -2.1725474 1.65971716 -0.6541599  0.67851684  1.2332285\n[3,]  0.2016110 0.02285655  1.5601640  0.28740146  0.4408304\n[4,] -0.4336983 1.71376570  0.8114271 -0.09984168 -0.4215189\n[5,] -0.1674907 0.78474944  0.3369209  2.14991398 -0.1129947\n\n\n[[2]]\n           [,1]        [,2]        [,3]        [,4]       [,5]\n[1,]  0.9770023  0.35882267  0.61710351 -2.09222637 -0.4720229\n[2,] -1.0516326  0.71649631 -0.43456077  0.22144536  0.4143916\n[3,]  0.2797802  0.33381043  0.47455349 -0.30597636  0.7987646\n[4,]  1.0352561  0.04053739 -0.71617305  0.06358775  0.5693680\n[5,] -0.2237260 -2.25343768 -0.05019352 -0.53390866 -0.6494792\n\n# Find the largest value in each vector using foreach in parallel\nlargest_values &lt;- foreach(vec = vectors, .combine = 'c') %dopar% {\n  # Apply max() correctly to each vector (make sure the result is combined as a vector of max values)\n  max_value &lt;- max(unlist(vec))  \n  max_value  # Return the largest value from each vector\n}\n\n# Stop the cluster after computation is done\nstopCluster(cl)\n\n# Print the largest values\nprint(largest_values)\n\n[1] 2.653670 1.035256",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Q1</span>"
    ]
  },
  {
    "objectID": "ParallelPrac.html#q5",
    "href": "ParallelPrac.html#q5",
    "title": "2  Q1",
    "section": "2.4 Q5",
    "text": "2.4 Q5\nlibrary(foreach)\nlibrary(doParallel)  \nlibrary(iterators)    \nlibrary(parallel)     \nlibrary(tictoc)       \n\n\nset.seed(1234)\n\n# Register parallel \ncl &lt;- makeCluster(4)\nregisterDoParallel(cl)\n\ncreate_vectors &lt;- function() {\n  vectors &lt;- foreach(i = 1:3, .combine = 'list', .packages = 'iterators') %dopar% {\n    it &lt;- irnorm(5)  \n    unlist(sapply(1:5, function(x) nextElem(it)))  \n  }\n  return(vectors)\n}\n\n\ntic(\"parLapply execution\")\nvectors_parLapply &lt;- parLapply(cl, 1:3, function(i) {\n  library(iterators)  \n  it &lt;- irnorm(5)\n  unlist(sapply(1:5, function(x) nextElem(it)))\n})\nlargest_values_parLapply &lt;- sapply(vectors_parLapply, function(vec) max(unlist(vec)))\ntoc()\nparLapply execution: 0.03 sec elapsed\ntic(\"foreach execution\")\nvectors_foreach &lt;- create_vectors()\nlargest_values_foreach &lt;- foreach(vec = vectors_foreach, .combine = 'c') %dopar% {\n  max(unlist(vec))\n}\ntoc()\nforeach execution: 0.06 sec elapsed\ntic(\"replicate execution\")\nvectors_replicate &lt;- replicate(3, unlist(sapply(1:5, function(x) rnorm(1))), simplify = FALSE)\nlargest_values_replicate &lt;- sapply(vectors_replicate, function(vec) max(vec))\ntoc()\nreplicate execution: 0 sec elapsed\nstopCluster(cl)\n\nMetrics&lt;-c(\"Largest values from parLapply:\",\"\",\"\",\"Largest values from foreach:\",\"\",\"Largest values from replicate:\",\"\",\"\")\nValues&lt;-c(largest_values_parLapply,largest_values_foreach,largest_values_replicate)\n\nknitr::kable(data.frame(Metrics,Values),digits = 2,caption = \"Question 5\")\n\nQuestion 5\n\n\nMetrics\nValues\n\n\n\n\nLargest values from parLapply:\n2.50\n\n\n\n2.01\n\n\n\n1.70\n\n\nLargest values from foreach:\n1.71\n\n\n\n1.73\n\n\nLargest values from replicate:\n1.08\n\n\n\n0.51\n\n\n\n0.96",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Q1</span>"
    ]
  }
]