[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Parallel Practical",
    "section": "",
    "text": "1 Welcome to Parallel Prac\nGitHub Link",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome to Parallel Prac</span>"
    ]
  },
  {
    "objectID": "ParallelPrac.html",
    "href": "ParallelPrac.html",
    "title": "2  Q1",
    "section": "",
    "text": "2.1 Q2\n# Load necessary packages\nlibrary(MASS)\nlibrary(foreach)\nlibrary(doParallel)\n\n# Set up parallel processing (3 cores in this example)\ncl &lt;- makeCluster(3)\nregisterDoParallel(cl)\n\n# Define the bootstrap function that calculates the median\nbootstrapMedian &lt;- function(data, n) {\n  # Sample 'n' elements from the data with replacement\n  sample_data &lt;- sample(data, size = n, replace = TRUE)\n  return(median(sample_data))\n}\n\n\n# Run bootstrapping serially\nset.seed(42)  # For reproducibility\nsystem.time({\n  bootstrapped_medians_serial &lt;- sapply(1:1000, function(x) bootstrapMedian(galaxies, n = 82))\n})\n\n   user  system elapsed \n   0.09    0.01    0.11 \n\n# Output a sample of the results\nprint(head(bootstrapped_medians_serial))\n\n[1] 20205.5 20208.5 20846.0 20522.0 20846.0 20221.0\n\n# Run bootstrapping in parallel\n# Set up parallel computing\nlibrary(doParallel)\ncl &lt;- makeCluster(4)  # Create a cluster with 4 workers\nregisterDoParallel(cl)\n\n# Run bootstrapping in parallel\nset.seed(42)  # For reproducibility\nsystem.time({\n  bootstrapped_medians_parallel &lt;- foreach(i = 1:1000, .combine = c, .packages = \"MASS\") %dopar% {\n    bootstrapMedian(galaxies, n = 82)\n  }\n})\n\n   user  system elapsed \n   0.55    0.11    1.06 \n\n# Stop the cluster after finishing\nstopCluster(cl)\n\n# Output a sample of the results\nprint(head(bootstrapped_medians_parallel))\n\n[1] 21137.0 20848.0 21492.0 20833.5 21239.0 21653.0\nFor the current bootstrapping task with the galaxies dataset, serial execution is faster due to the small task size and the cost of parallelization overhead. If you were processing much larger datasets or running more complex computations, you would likely see greater benefits from parallelization.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Q1</span>"
    ]
  },
  {
    "objectID": "ParallelPrac.html#q3",
    "href": "ParallelPrac.html#q3",
    "title": "2  Q1",
    "section": "2.2 Q3",
    "text": "2.2 Q3\n\nset.seed(42)  # For reproducibility\n\n# Step 1: Generate the original sample (size 50 from exponential distribution)\noriginal_sample &lt;- rexp(50, rate = 1)  # Exponential distribution with mean = 1\n\n\nbootstrap_mean &lt;- function(sample, n_iterations = 1000) {\n  bootstrap_stats &lt;- numeric(n_iterations)\n  \n  for (i in 1:n_iterations) {\n    bootstrap_sample &lt;- sample(sample, replace = TRUE)\n    bootstrap_stats[i] &lt;- mean(bootstrap_sample)  # Calculating the mean for each bootstrap sample\n  }\n  \n  return(bootstrap_stats)\n}\n\n# Step 3: Perform bootstrap resampling\nn_iterations &lt;- 1000\nbootstrap_stats &lt;- bootstrap_mean(original_sample, n_iterations)\n\n# Step 4: Compute percentile-based confidence interval\nlower_percentile &lt;- 2.5\nupper_percentile &lt;- 97.5\n\nlower_bound &lt;- quantile(bootstrap_stats, lower_percentile / 100)\nupper_bound &lt;- quantile(bootstrap_stats, upper_percentile / 100)\n\n# True value \ntrue_value &lt;- 1\n\n# Step 5: Estimate coverage\ncoverage &lt;- ifelse(true_value &gt;= lower_bound & true_value &lt;= upper_bound, 1, 0)\n\n# Repeat the process to estimate coverage over multiple trials\nn_trials &lt;- 1000\ncoverage_results &lt;- numeric(n_trials)\n\nfor (i in 1:n_trials) {\n  bootstrap_stats &lt;- bootstrap_mean(original_sample, n_iterations)\n  lower_bound &lt;- quantile(bootstrap_stats, lower_percentile / 100)\n  upper_bound &lt;- quantile(bootstrap_stats, upper_percentile / 100)\n  coverage_results[i] &lt;- ifelse(true_value &gt;= lower_bound & true_value &lt;= upper_bound, 1, 0)\n}\n\n# Coverage estimate (proportion of times true value is inside the confidence interval)\ncoverage_estimate &lt;- mean(coverage_results)\ncoverage_estimate\n\n[1] 1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Q1</span>"
    ]
  },
  {
    "objectID": "ParallelPrac.html#q4",
    "href": "ParallelPrac.html#q4",
    "title": "2  Q1",
    "section": "2.3 Q4",
    "text": "2.3 Q4\n\n# Load necessary packages\nlibrary(foreach)\nlibrary(doParallel)  # For parallel processing\nlibrary(iterators)    # For irnorm function\n\n# Set the seed for reproducibility\nset.seed(1234)\n\n# Register parallel backend (4 workers in this case)\ncl &lt;- makeCluster(4)\nregisterDoParallel(cl)\n\n# Create a list of 3 vectors, each containing 5 random variables from a normal distribution\nvectors &lt;- foreach(i = 1:3, .combine = 'list', .packages = 'iterators') %dopar% {\n  it &lt;- irnorm(5)  # Create an iterator for 5 random normal variables\n  unlist(sapply(1:5, function(x) nextElem(it)))  # Extract the values from the iterator\n}\n\n# Print the vectors to check\nprint(vectors)\n\n[[1]]\n[[1]][[1]]\n           [,1]       [,2]        [,3]       [,4]       [,5]\n[1,] -0.8882516  0.5530257  0.50804781  0.5319570  0.1274931\n[2,]  1.8419585  0.1807020  2.12615105 -0.1965465  2.1854988\n[3,] -0.4582521 -0.3668049 -0.78095864  0.9243293 -0.8228405\n[4,] -1.1088474  1.2658526 -0.02627349 -0.8433929 -0.4368993\n[5,]  0.3618803  0.1623761 -0.61118021 -1.7706468 -1.4526011\n\n[[1]][[2]]\n           [,1]       [,2]        [,3]       [,4]       [,5]\n[1,]  2.2375147  1.0848369 -0.32825899 -0.6467536 -0.3309042\n[2,]  1.2092702 -1.1638105  0.62166049 -0.3888259  0.7053950\n[3,] -1.2746993 -0.3643742 -1.31675076  0.2395872 -0.9352317\n[4,]  1.0542090 -1.3586677  0.86780683 -0.8696557  1.0907645\n[5,]  0.5076115 -0.2834928  0.02659456  0.9705340 -0.6549447\n\n\n[[2]]\n           [,1]       [,2]       [,3]        [,4]       [,5]\n[1,]  0.3957007  0.2659157  0.4224899 -0.28232056 -0.7491363\n[2,]  0.2893169  0.1986392  1.3502966 -0.53405652 -0.2401563\n[3,] -0.2599960 -0.1318797 -1.4604409  0.76693652  0.6732195\n[4,]  1.4035346  1.9477988  1.3759127 -0.05135932  0.5511672\n[5,] -0.1688861 -0.3719002 -0.5504700  0.13930371  0.3415042\n\n# Find the largest value in each vector using foreach in parallel\nlargest_values &lt;- foreach(vec = vectors, .combine = 'c') %dopar% {\n  # Apply max() correctly to each vector (make sure the result is combined as a vector of max values)\n  max_value &lt;- max(unlist(vec))  \n  max_value  # Return the largest value from each vector\n}\n\n# Stop the cluster after computation is done\nstopCluster(cl)\n\n# Print the largest values\nprint(largest_values)\n\n[1] 2.237515 1.947799",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Q1</span>"
    ]
  },
  {
    "objectID": "ParallelPrac.html#q5",
    "href": "ParallelPrac.html#q5",
    "title": "2  Q1",
    "section": "2.4 Q5",
    "text": "2.4 Q5\n\n# Load necessary packages\nlibrary(foreach)\nlibrary(doParallel)  # For parallel processing\nlibrary(iterators)    # For irnorm function\nlibrary(parallel)     # For parLapply\nlibrary(tictoc)       # For timing execution\n\n# Set the seed for reproducibility\nset.seed(1234)\n\n# Register parallel backend (4 workers in this case) for foreach\ncl &lt;- makeCluster(4)\nregisterDoParallel(cl)\n\n# Function to create random vectors\ncreate_vectors &lt;- function() {\n  vectors &lt;- foreach(i = 1:3, .combine = 'list', .packages = 'iterators') %dopar% {\n    it &lt;- irnorm(5)  # Create an iterator for 5 random normal variables\n    unlist(sapply(1:5, function(x) nextElem(it)))  # Extract the values from the iterator\n  }\n  return(vectors)\n}\n\n# 1. parLapply method (make sure the iterators package is available on the worker nodes)\ntic(\"parLapply execution\")\nvectors_parLapply &lt;- parLapply(cl, 1:3, function(i) {\n  library(iterators)  # Ensure the iterators package is loaded on each worker\n  it &lt;- irnorm(5)\n  unlist(sapply(1:5, function(x) nextElem(it)))\n})\nlargest_values_parLapply &lt;- sapply(vectors_parLapply, function(vec) max(unlist(vec)))\ntoc()\n\nparLapply execution: 0.04 sec elapsed\n\n# 2. foreach method (parallel)\ntic(\"foreach execution\")\nvectors_foreach &lt;- create_vectors()\nlargest_values_foreach &lt;- foreach(vec = vectors_foreach, .combine = 'c') %dopar% {\n  max(unlist(vec))\n}\ntoc()\n\nforeach execution: 0.08 sec elapsed\n\n# 3. replicate method (sequential)\ntic(\"replicate execution\")\nvectors_replicate &lt;- replicate(3, unlist(sapply(1:5, function(x) rnorm(1))), simplify = FALSE)\nlargest_values_replicate &lt;- sapply(vectors_replicate, function(vec) max(vec))\ntoc()\n\nreplicate execution: 0.02 sec elapsed\n\n# Stop the cluster after computation is done\nstopCluster(cl)\n\n# Print the results\nprint(\"Largest values from parLapply:\")\n\n[1] \"Largest values from parLapply:\"\n\nprint(largest_values_parLapply)\n\n[1] 2.584873 3.033492 1.381301\n\nprint(\"Largest values from foreach:\")\n\n[1] \"Largest values from foreach:\"\n\nprint(largest_values_foreach)\n\n[1] 2.043208 1.753531\n\nprint(\"Largest values from replicate:\")\n\n[1] \"Largest values from replicate:\"\n\nprint(largest_values_replicate)\n\n[1] 1.0844412 0.5060559 0.9594941",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Q1</span>"
    ]
  }
]